---
layout: home
profile_picture:
  src: /assets/img/profile-pic.jpg
  alt: website picture
---
## <span style="color: Green">About me:</span>
**Vipul Arora**
<br>Associate Professor
<br>Department of Electrical Engineering
<br>IIT Kanpur
<br>Email: vipul ar (AT) iitk (.) ac (.) in
<br>**Postal Address:** 305-D, ACES building, IIT Kanpur - 208016 ([<ins>map</ins>](https://www.google.com/maps/place/ACES+%2F+Electrical+Engineering+Department/@26.5130198,80.2321879,19.65z/data=!4m5!3m4!1s0x399c36fe1e36c67f:0x13c8303ef646955!8m2!3d26.5129531!4d80.2320872))
<br>**Office location:** Sustainable Energy Engineering Building, Near Media Labs ([<ins>map</ins>](https://www.google.com/maps/dir//26.5100321,80.2356058/@26.5100738,80.2356058,38m/data=!3m1!1e3!4m2!4m1!3e0))

I received my B.Tech. and Ph.D. degrees in [<ins>Electrical Engineering</ins>](http://www.iitk.ac.in/ee/) from the [<ins>Indian Institute of Technology (IIT) Kanpur</ins>](http://www.iitk.ac.in/), India. My Ph.D. thesis was titled "[<ins>Analysis of Pitched Polyphonic Music for Source Transcription</ins>](https://drive.google.com/file/d/0By8wZfM49Y2ScC1vc2lVX0I1c1U/view)", where I worked on analyzing music audio to identify and transcribe different instruments/voices playing simultaneously. During postdoc at Oxford University (UK), I developed [<ins>speech recognition</ins>](https://www.youtube.com/watch?v=Tgr3Y_U9BsQ) systems using linguistic principles, with applications in automatic language teacher and speech recognition for low-resource languages. At Amazon in Boston (USA), I worked on audio classification for developing Alexa [<ins>home security</ins>](https://www.theverge.com/2018/9/20/17883428/amazon-alexa-guard-alarm-ring-smart-home-security-price) system, with research focusing on classification with imbalanced data.

### Research interests:
- Machine learning for audio signal processing
  - audio retrieval: multi-label classification
  - melody estimation: transfer learning
  - speech recognition: confidence estimation
  - music analysis: explainable AI
- Machine learning for Physics 
  - generative modeling, normalizing flows, adversarial learning
- Time series analysis on sensor data
  - domain adaptation, semi-supervised learning

## <span style="color: Green">Opportunities:</span>

- Available [UG projects](stuff/2022_UGPs.md) (June 2022)
- Job Openings:
  - We are looking for postdocs and senior researchers. If interested, send me an email. (Dec 2022)
  - We are looking for research associates to work on research and deployment for public use. If interested, send me an email. (Dec 2022)

## <span style="color: green">Projects:</span>
### Ongoing
- [Automatic Speech Recognition](https://vipular.github.io/stuff/2021_PrasarBharatiProjects.html) by Prasar Bharati
- [Audio Archival Content Retrieval](https://vipular.github.io/stuff/2021_PrasarBharatiProjects.html) by Prasar Bharati
- [Spoken Term Detection (Voice Search)](stuff/2022_nltmProject) by NLTM
- [Machine Learning for lattice theories in Physics]() core research grant from DST
- [Automatic Music Tutor](https://vipular.github.io/narottam.github.io) by IMPRINT
- [Sensor Calibration](https://vipular.github.io/stuff/2021_sensorcalibration.html) ML based calibration of air quality sensors by Maharashtra Pollution Control Board
- [Machine Learning for Lattice Quantum Chromodynamics]() funded by SPARC, collaboration with Prof. W. Detmold and Prof. P. Shanahan, MIT
- [Digitizing and AI-fying Maternity Care in Rural India]() funded by Google AI for Social Good program

## <span style="color: Green">News:</span>  

| |
| -- |
| 14 July 2022: <br>**Paper accepted at ISMIR 2022**: Attention-Based Audio Embeddings for Query-by-Example |
| 20 May 2022: <br>**[Music Course](stuff/2022_musicCourse)**: Learn music with computer assistance tools |
| 22 Feb 2022: <br>**[NLTM](stuff/2022_nltmProject)**: Grant for Spoken Term Detection from National Language Technologies Mission |
| 27 Aug 2021: <br>**[First position in NEC 2021 Grand Challenge](https://www.neuroergonomicsconference.um.ifi.lmu.de/pbci/)**: Passive BCI Hackathon to decode mental workload from EEG signals. Team: Swapnil Singh, Vartika Gupta, Tharun Kumar Reddy, Vipul Arora |
| 11 Aug 2021: <br>**[Second position in IEEE ICAS 2021 Challenge](https://2021.ieee-icas.org/challenge/)**: Self-awareness in heterogeneous multi-robot systems. Team: Nitish Vikas Deshpande, Afzal Rao, Adhiraj Banerjee, Vipul Arora |
| 19 July 2021: <br>**Two grants from Prasar Bharati:** Received two grants, titled, "Automatic Speech Recognition for Speech Subtitling (Making Broadcast Content in various Indian Languages Accessible)" and "Archival Content Retrieval through Audio and Text Query" from Prasar Bharati |
| 17 June 2021: <br>**[Article in Hindustan Times](https://www.hindustantimes.com/opinion/measuring-indoor-air-pollution-why-low-cost-technology-is-critical-101623911895014.html)** "Measuring indoor air pollution: Why low-cost technology is critical", Opinion Edition, S.N. Tripathi and Vipul Arora. |
| 25 May 2021: <br>**[Google AI4SG Award](https://sites.google.com/view/aiforsocialgoodworkshop/2021-projects?authuser=0)**: Research proposal with IITK consult group and CARE India NGO, titled "AI-based Smart Assistant for Child Deliveries in Low Resource Areas", selected to be a part of Google’s AI for Social Good program for 2021-22. |
| 11 May 2021: <br>**[Paper accepted in NCC 2021](https://www.iitk.ac.in/ncc2021/)** Aman Sharma, Kavya Saxena and Vipul Arora, "Frequency-Anchored Deep Networks for Polyphonic Melody Extraction", in Proceedings of National Conference on Communications, 2021. |
| 6 Mar 2021: <br>**Paper accepted in [Scipost journal](https://www.scipost.org/)**: Japneet Singh, Mathias S. Scheurer, and Vipul Arora. "Conditional generative models for sampling and phase transition indication in spin systems." Scipost, 2021. |
| 22 Jan 2021: <br>**Positions secured in [International BCI competition organized by IEEE Brain](http://brain.korea.ac.kr/bci2021/competition.php)**:<br>-	1st position in few shot learning track <br>-	1st position in microsleep detection <br>-	3rd position in EEG based ERP detection <br>-	4th position in upper limb movements decoding <br>-	7th position in imagined sleep classification <br> Team members: Dr. Tharun Reddy, Madhurdeep Jain, Jinang Shah, Palashdeep Singh,  Vartika Gupta, Kushangi Mittal, Archit Bansal, Chittoor Murari|
| 3 Dec 2020: <br>**Paper accepted in IEEE CICT 2020**: Shivangi Ranjan and Vipul Arora, "A Bioinformatic Method Of Semi-Global Alignment For Query-By-Humming", in IEEE Conference on Information and Communication Technology (CICT), 2020, pp. 1–5 |
| 24 July 2020: <br>**Clinical BCI Challenge 2020**: Our team (named iBCI) secured overall 2nd position in [Clinical BCI Challenge at IEEE WCCI 2020](https://sites.google.com/view/bci-comp-wcci/) |
| 9 July 2020: <br>**Grant approved by MPCB**: "Technical Assessment of Low-Cost Sensor based PM2.5 and PM10 Monitoring Network in Maharashtra" |
| 25 Apr 2020: <br>**SP Cup 2020**: Our team secured 6th position in [IEEE Signal Processing Cup competition 2020](https://signalprocessingsociety.org/community-involvement/signal-processing-cup) |
| 21 Mar 2020: <br>**Paper accepted in FUZZ-IEEE 2020**: Tharun Kumar Reddy, Vipul Arora, Laxmidhar Behera, Yukai Wang and Chin Teng Lin, "Fuzzy Divergence Based Analysis For EEG Drowsiness Detection Brain Computer Interfaces ", IEEE International Conference on Fuzzy Systems, 2020. |
| 24 Jan 2020:<br>**Paper accepted in ICASSP 2020**: Satyam Kumar, Tharun Kumar Reddy, Vipul Arora, and Laxmidhar Behera, "Formulating Divergence Framework For Multiclass Motor Imagery EEG Brain Computer Interface", IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020. |
| 11 Nov 2019:<br>**ASEM DUO 2020 Professor Fellowship Award**: for research exchange with University of Surrey, UK |
| 28 June 2019:<br>**IMPRINT-2C grant approved**: "Smart music tutor for Indian classical music" |
| 15 May 2019:<br>**Paper presented in ICASSP 2019**: Vipul Arora, Ming Sun and Chao Wang, "Deep Embeddings for Rare Audio Event Detection With Imbalanced Data", IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019. [[poster]](https://sigport.org/sites/default/files/docs/POSTER_vipul_0.pdf) |
| 13 May 2019:<br>**General Linguistics Seminar Talk at University of Oxford**: titled "Modern speech technologies and applications of phonology. |
| 1 May 2019:<br>**Initiation grant approved**: "Machine Learning for Physics |
| 6 Feb 2019: <br>**SPARC grant approved**: Collaboration project between IITK and MIT, titled "Machine Learning for Lattice Quantum Chromodynamics" |
| 1 Feb 2019:<br>**Paper accepted in ICASSP 2019**: Vipul Arora, Ming Sun and Chao Wang, "Deep Embeddings for Rare Audio Event Detection With Imbalanced Data", IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019. [[pdf]](https://drive.google.com/file/d/1Z7wCbKnz1YqvVVmQF40FeXUGIrpkgY3t/view) [[blog]](https://www.amazon.science/blog/to-correct-imbalances-in-training-data-dont-oversample-cluster) |

<br/>






<!--
- <span style="color: DarkRed">Opening for a research scientist/engineer in music processing [apply here](https://forms.office.com/r/KKj7294qtf)</span>
-->

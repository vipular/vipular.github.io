I"û<h2 id="about-me">About me:</h2>
<p>I received my B.Tech. and Ph.D. degrees in <a href="http://www.iitk.ac.in/ee/"><ins>Electrical Engineering</ins></a> from the <a href="http://www.iitk.ac.in/"><ins>Indian Institute of Technology (IIT) Kanpur</ins></a>, India. My Ph.D. thesis was titled ‚Äú<a href="https://drive.google.com/file/d/0By8wZfM49Y2ScC1vc2lVX0I1c1U/view"><ins>Analysis of Pitched Polyphonic Music for Source Transcription</ins></a>‚Äù, where I worked on analyzing music audio to identify and transcribe different instruments/voices playing simultaneously. During postdoc at Oxford University (UK), I developed <a href="https://www.youtube.com/watch?v=Tgr3Y_U9BsQ"><ins>speech recognition</ins></a> systems using linguistic principles, with applications in automatic language teacher and speech recognition for low-resource languages. At Amazon in Boston (USA), I worked on audio classification for developing Alexa <a href="https://www.theverge.com/2018/9/20/17883428/amazon-alexa-guard-alarm-ring-smart-home-security-price"><ins>home security</ins></a> system, with research focusing on classification with imbalanced data.</p>

<p><span style="color: blue"><b>Research interests:</b> machine learning, signal processing and optimization</span></p>

<h2 id="opportunities"><span style="color: Green">Opportunities</span></h2>
<ul>
  <li><span style="color: DarkRed">Undergraduate students looking for projects with me please see <a href="https://iitk-my.sharepoint.com/:w:/g/personal/vipular_iitk_ac_in/Eb4MuskFBA9HlN2erjHe40IBivflK4v7Dj1ZNRdYX8id6A?rtime=E22O2beh2Eg"><ins>this</ins></a></span></li>
</ul>

<h2 id="research"><span style="color: green">Research</span></h2>

<p><span style="color: blue">I am focusing mainly on the following areas:</span></p>
<ul>
  <li>Machine learning for music analysis</li>
  <li>Machine learning for physics</li>
  <li>Machine learning for natural language processing(text)</li>
</ul>

<h2 id="news"><span style="color: Green">News:</span></h2>

<table>
  <tbody>
    <tr>
      <td>24 July 2020: <br /><strong>Clinical BCI Challenge 2020</strong>: Our team (named iBCI) secured overall 2nd position in <a href="https://sites.google.com/view/bci-comp-wcci/">Clinical BCI Challenge at IEEE WCCI 2020</a></td>
    </tr>
    <tr>
      <td>9 July 2020: <br /><strong>Grant approved by MPCB</strong>: ‚ÄúTechnical Assessment of Low-Cost Sensor based PM2.5 and PM10 Monitoring Network in Maharashtra‚Äù</td>
    </tr>
    <tr>
      <td>25 Apr 2020: <br /><strong>SP Cup 2020</strong>: Our team secured 6th position in <a href="https://signalprocessingsociety.org/community-involvement/signal-processing-cup">IEEE Signal Processing Cup competition 2020</a></td>
    </tr>
    <tr>
      <td>21 Mar 2020: <br /><strong>Paper accepted in FUZZ-IEEE 2020</strong>: Tharun Kumar Reddy, Vipul Arora, Laxmidhar Behera, Yukai Wang and Chin Teng Lin, ‚ÄúFuzzy Divergence Based Analysis For EEG Drowsiness Detection Brain Computer Interfaces ‚Äú, IEEE International Conference on Fuzzy Systems, 2020.</td>
    </tr>
    <tr>
      <td>24 Jan 2020:<br /><strong>Paper accepted in ICASSP 2020</strong>: Satyam Kumar, Tharun Kumar Reddy, Vipul Arora, and Laxmidhar Behera, ‚ÄúFormulating Divergence Framework For Multiclass Motor Imagery EEG Brain Computer Interface‚Äù, IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2020.</td>
    </tr>
    <tr>
      <td>11 Nov 2019:<br /><strong>ASEM DUO 2020 Professor Fellowship Award</strong>: for research exchange with University of Surrey, UK</td>
    </tr>
    <tr>
      <td>28 June 2019:<br /><strong>IMPRINT-2C grant approved</strong>: ‚ÄúSmart music tutor for Indian classical music‚Äù</td>
    </tr>
    <tr>
      <td>15 May 2019:<br /><strong>Paper presented in ICASSP 2019</strong>: Vipul Arora, Ming Sun and Chao Wang, ‚ÄúDeep Embeddings for Rare Audio Event Detection With Imbalanced Data‚Äù, IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019. <a href="https://sigport.org/sites/default/files/docs/POSTER_vipul_0.pdf">[poster]</a></td>
    </tr>
    <tr>
      <td>13 May 2019:<br /><strong>General Linguistics Seminar Talk at University of Oxford</strong>: titled ‚ÄúModern speech technologies and applications of phonology.</td>
    </tr>
    <tr>
      <td>1 May 2019:<br /><strong>Initiation grant approved</strong>: ‚ÄúMachine Learning for Physics</td>
    </tr>
    <tr>
      <td>6 Feb 2019: <br /><strong>SPARC grant approved</strong>: Collaboration project between IITK and MIT, titled ‚ÄúMachine Learning for Lattice Quantum Chromodynamics‚Äù</td>
    </tr>
    <tr>
      <td>1 Feb 2019:<br /><strong>Paper accepted in ICASSP 2019</strong>: Vipul Arora, Ming Sun and Chao Wang, ‚ÄúDeep Embeddings for Rare Audio Event Detection With Imbalanced Data‚Äù, IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), 2019. <a href="https://drive.google.com/file/d/1Z7wCbKnz1YqvVVmQF40FeXUGIrpkgY3t/view">[pdf]</a> <a href="https://www.amazon.science/blog/to-correct-imbalances-in-training-data-dont-oversample-cluster">[blog]</a></td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<h2 id="contact-me"><span style="color: Green">Contact me:</span></h2>
<p><strong>Dr. Vipul Arora</strong>
<br />Assistant Professor
<br />Department of Electrical Engineering
<br />IIT Kanpur
<br /><strong>Office:</strong> 305D, ACES building 
<br /><strong>Links:</strong> <a href="https://www.youtube.com/channel/UCkbiCBHj4DrTo2SXboR7fOw">Youtube</a></p>

:ET